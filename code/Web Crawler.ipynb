{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些版是18+的，所以要多一些判定。  \n",
    "normal 200頁 40min  \n",
    "18+    200頁 1h30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:11:35.372805Z",
     "start_time": "2020-01-02T04:11:35.368815Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# for normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T09:27:29.352362Z",
     "start_time": "2020-01-02T08:44:06.986454Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "cur_page = 'https://www.ptt.cc/bbs/movie/index8671.html'\n",
    "next_page =''\n",
    "\n",
    "with open('movie_max.csv', 'w', errors='ignore',newline='') as csvfile:\n",
    "    \n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    for i in range(1,201):        #this to control num of pages\n",
    "        article_url = []\n",
    "        article_vote = []\n",
    "        article_context = []\n",
    "        article_time = []\n",
    "        article_title=[]\n",
    "        false_index = []\n",
    "        table = []\n",
    "    \n",
    "        res = requests.get(cur_page, verify=False)\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        res.close()\n",
    "    \n",
    "        next_page = 'https://www.ptt.cc'+soup.select('.action-bar')[0].find_all('a')[3]['href']\n",
    "        for entry in soup.select('.r-ent'):\n",
    "            if not entry.find('a'):\n",
    "                continue\n",
    "            article_vote.append(entry.select('.nrec')[0].text)\n",
    "            article_title.append(entry.select('.title')[0].text)\n",
    "            article_url.append('https://www.ptt.cc'+entry.find('a')['href'])\n",
    "        \n",
    " \n",
    "        for i,page in enumerate(article_url):\n",
    "            res_loop = requests.get(page, verify=False)\n",
    "            soup_loop = BeautifulSoup(res_loop.text)\n",
    "            res_loop.close()\n",
    "            \n",
    "            if (len(soup_loop.select('.article-meta-value'))!=4):\n",
    "                false_index.append(i)\n",
    "                continue\n",
    "            if not soup_loop.find(id=\"main-content\"):\n",
    "                false_index.append(i)\n",
    "                continue    \n",
    "                \n",
    "            content = soup_loop.find(id=\"main-content\").text\n",
    "            delete_content_1 = u'※ 發信站: 批踢踢實業坊(ptt.cc),'\n",
    "            delete_content_2 = soup_loop.select('.article-meta-value')[3].text\n",
    "            content = content.split(delete_content_1)\n",
    "            content = content[0].split(delete_content_2)\n",
    "            main_content = content[1].replace('--', '')     \n",
    "            \n",
    "            main_content = re.sub('\\n','\\n\\n',main_content)\n",
    "            main_content = re.sub('\\n[:※]+[^\\n:※]+\\n','',main_content)\n",
    "            main_content = re.sub('\\n\\n','\\n',main_content)\n",
    "            \n",
    "            article_context.append(main_content)\n",
    "            article_time.append(delete_content_2)\n",
    "        false_index.reverse()\n",
    "        for i in false_index:\n",
    "            del article_vote[i]\n",
    "            del article_title[i]\n",
    "            del article_url[i]\n",
    "    \n",
    "        table = [article_url,article_vote,article_context,article_time,article_title]\n",
    "        table = np.transpose(table).tolist()\n",
    "        writer.writerows(table)\n",
    "    \n",
    "    \n",
    "        cur_page = next_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# for 18+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T12:51:37.616770Z",
     "start_time": "2020-01-02T11:23:06.998621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "cur_page = 'https://www.ptt.cc/bbs/sex/index4005.html'\n",
    "next_page =''\n",
    "\n",
    "with open('sex_max.csv', 'w', errors='ignore',newline='') as csvfile:\n",
    "    \n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    for i in range(1,201):        #this to control num of pages\n",
    "        article_url = []\n",
    "        article_vote = []\n",
    "        article_context = []\n",
    "        article_time = []\n",
    "        article_title=[]\n",
    "        false_index = []\n",
    "        table = []\n",
    "        \n",
    "        payload = {'from': cur_page, 'yes':'yes'}\n",
    "        rs = requests.session()\n",
    "        res = rs.post('https://www.ptt.cc/ask/over18', verify=False, data=payload)\n",
    "        res = rs.get(cur_page, verify=False)\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        rs.close()\n",
    "    \n",
    "        next_page = 'https://www.ptt.cc'+soup.select('.action-bar')[0].find_all('a')[3]['href']\n",
    "        for entry in soup.select('.r-ent'):\n",
    "            if not entry.find('a'):\n",
    "                continue\n",
    "            article_vote.append(entry.select('.nrec')[0].text)\n",
    "            article_title.append(entry.select('.title')[0].text)\n",
    "            article_url.append('https://www.ptt.cc'+entry.find('a')['href'])\n",
    "        \n",
    " \n",
    "        for i,page in enumerate(article_url):\n",
    "        \n",
    "            payload = {'from': page, 'yes':'yes'}\n",
    "            rs = requests.session()\n",
    "            res = rs.post('https://www.ptt.cc/ask/over18', verify=False, data=payload)\n",
    "            res_loop = rs.get(page, verify=False)\n",
    "            soup_loop = BeautifulSoup(res_loop.text)\n",
    "            rs.close()\n",
    "            \n",
    "            if (len(soup_loop.select('.article-meta-value'))!=4):\n",
    "                false_index.append(i)\n",
    "                continue\n",
    "            if not soup_loop.find(id=\"main-content\"):\n",
    "                false_index.append(i)\n",
    "                continue\n",
    "            \n",
    "            content = soup_loop.find(id=\"main-content\").text\n",
    "            delete_content_1 = u'※ 發信站: 批踢踢實業坊(ptt.cc),'\n",
    "            delete_content_2 = soup_loop.select('.article-meta-value')[3].text\n",
    "            content = content.split(delete_content_1)\n",
    "            content = content[0].split(delete_content_2)\n",
    "            main_content = content[1].replace('--', '')     \n",
    "            \n",
    "            main_content = re.sub('\\n','\\n\\n',main_content)\n",
    "            main_content = re.sub('\\n[:※]+[^\\n:※]+\\n','',main_content)\n",
    "            main_content = re.sub('\\n\\n','\\n',main_content)\n",
    "            \n",
    "            article_context.append(main_content)\n",
    "            article_time.append(delete_content_2)\n",
    "        false_index.reverse()\n",
    "        for i in false_index:\n",
    "            del article_vote[i]\n",
    "            del article_title[i]\n",
    "            del article_url[i]\n",
    "    \n",
    "        table = [article_url,article_vote,article_context,article_time,article_title]\n",
    "        table = np.transpose(table).tolist()\n",
    "        writer.writerows(table)\n",
    "    \n",
    "    \n",
    "        cur_page = next_page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
