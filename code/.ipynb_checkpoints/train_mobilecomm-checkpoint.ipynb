{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP & train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:10:53.085103Z",
     "start_time": "2020-01-08T11:10:49.182641Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f = open('mobilecomm_max.csv')\n",
    "df= pd.read_csv(f, header = None)\n",
    "df = df.fillna('0')\n",
    "\n",
    "X = df.iloc[:, 2].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:10:53.385272Z",
     "start_time": "2020-01-08T11:10:53.089060Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing : extracting feature vector from X_train\n",
    "# 拿掉換行和標點符號\n",
    "import re\n",
    "from zhon.hanzi import punctuation\n",
    "import string\n",
    "\n",
    "eng_punc = string.punctuation\n",
    "def preprocessor(text):\n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    re_punctuation = \"[{}]+\".format(punctuation)  #拿掉中文標點\n",
    "    text = re.sub(re_punctuation, \"\", text)\n",
    "    \n",
    "    re_punctuation_eng = \"[{}]+\".format(eng_punc) #拿掉英文標點\n",
    "    text = re.sub(re_punctuation_eng, \"\", text)    \n",
    "    \n",
    "    ptt_punc = '\\n\\t ※'\n",
    "    re_punctuation_ptt = \"[{}]+\".format(ptt_punc) #拿掉其他無用字元\n",
    "    text = re.sub(re_punctuation_ptt, \"\", text)  \n",
    "    \n",
    "    text = re.sub('[0-9A-Za-z]+','',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X[i] = preprocessor(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:11:13.949738Z",
     "start_time": "2020-01-08T11:10:53.388262Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\User\\Desktop\\pytry\\final\\train_all\\jieba_dict\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.u4dc008d2500e3c796bdd282f2ecbc9e7.cache\n",
      "Loading model cost 1.374 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing : tf-idf using jieba\n",
    "# preprocessing : 移除stop word\n",
    "import jieba.analyse\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary(\"jieba_dict/dict.txt.big.txt\")\n",
    "tags = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    tags.append(jieba.analyse.extract_tags(X[i], topK=50, withWeight=True))\n",
    "stopWords = []\n",
    "with open('stop_word/stop_word.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data)\n",
    "        \n",
    "X_cut = X\n",
    "X_cut_stop = X\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X_cut[i] = jieba.cut(X[i], cut_all=False)\n",
    "    X_cut_stop[i] = list(filter(lambda a: a not in stopWords and a != '\\n', X_cut[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:11:13.972704Z",
     "start_time": "2020-01-08T11:11:13.952734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nfor i in range(0, len(y)):\\n    if y[i] == '爆':\\n        y[i] = 1\\n    elif y[i][0] == 'X':\\n        y[i] = 0\\n    else:\\n        y[i] = int(y[i])\\n        if y[i] == 0:\\n            y[i] = 0\\n        elif y[i] >= 1 and y[i] <= 10:\\n            y[i] = 0\\n        elif y[i] >= 11 and y[i] <= 50:\\n            y[i] = 1\\n        elif y[i] >= 51 and y[i] <= 99:\\n            y[i] = 1\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing : labeling y_train\n",
    "# encoding of 推噓 : \n",
    "import math\n",
    "\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == '爆':\n",
    "        y[i] = 3\n",
    "    elif y[i][0] == 'X':\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = int(y[i])\n",
    "        if y[i] == 0:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 1 and y[i] <= 10:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 11 and y[i] <= 50:\n",
    "            y[i] = 2\n",
    "        elif y[i] >= 51 and y[i] <= 99:\n",
    "            y[i] = 3\n",
    "'''    \n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == '爆':\n",
    "        y[i] = 1\n",
    "    elif y[i][0] == 'X':\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = int(y[i])\n",
    "        if y[i] == 0:\n",
    "            y[i] = 0\n",
    "        elif y[i] >= 1 and y[i] <= 10:\n",
    "            y[i] = 0\n",
    "        elif y[i] >= 11 and y[i] <= 50:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 51 and y[i] <= 99:\n",
    "            y[i] = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:13:59.345980Z",
     "start_time": "2020-01-08T11:11:13.979661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing : 轉換成NTLK可以使用的格式\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "X_cut_NTLK = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    article = ''\n",
    "    for word in X_cut_stop[i]:\n",
    "        article = article + word\n",
    "        article = article + ' '\n",
    "    X_cut_NTLK = np.hstack((X_cut_NTLK, article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:00.149371Z",
     "start_time": "2020-01-08T11:13:59.348974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing : Bag of Word\n",
    "# Preprocessing : Term frequency - inverse document frequency (tf - idf) using NTLK\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(max_features=1000)\n",
    "bag = count.fit_transform(X_cut_NTLK)\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf = True,\n",
    "                         norm = 'l2',\n",
    "                         smooth_idf = True)\n",
    "X_bag_idf = tfidf.fit_transform(bag)\n",
    "print(X_bag_idf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:00.157349Z",
     "start_time": "2020-01-08T11:14:00.150366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3949\n",
      "3949\n"
     ]
    }
   ],
   "source": [
    "print(y.shape[0])\n",
    "print(X_bag_idf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:00.191261Z",
     "start_time": "2020-01-08T11:14:00.160342Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [  18 2105 1622  204]\n",
      "Labels counts in y_train: [  13 1473 1135  143]\n",
      "Labels counts in y_test: [  5 632 487  61]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = y.astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_bag_idf, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:00.336872Z",
     "start_time": "2020-01-08T11:14:00.193252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2764\n",
      "1185\n",
      "3949\n",
      "3949\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.toarray()[:,0]))\n",
    "print(len(X_test.toarray()[:,0]))\n",
    "\n",
    "X_all = np.concatenate((X_train.toarray(),X_test.toarray()),axis=0)\n",
    "y_all = np.concatenate((y_train,y_test))\n",
    "\n",
    "print(len(X_all[:,0]))\n",
    "print(len(y_all))\n",
    "\n",
    "group = np.zeros(len(y_all), dtype=np.int)\n",
    "group[0:len(X_train.toarray()[:,0])] = group[0:len(X_train.toarray()[:,0])]+1\n",
    "df_re = pd.DataFrame(X_all)\n",
    "df_re['label'] = y_all\n",
    "df_re['group'] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:00.717865Z",
     "start_time": "2020-01-08T11:14:00.339862Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label 分布: [1473 1473 1473 1473]\n",
      "test label 分布: [  5 632 487  61]\n",
      "評分標準(只猜一群): 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_0 = df_re[df_re.group==1][df_re.label==0]\n",
    "df_1 = df_re[df_re.group==1][df_re.label==1]\n",
    "df_2 = df_re[df_re.group==1][df_re.label==2]\n",
    "df_3 = df_re[df_re.group==1][df_re.label==3]\n",
    "\n",
    "df_0 = resample(df_0, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_1 = resample(df_1, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_2 = resample(df_2, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_3 = resample(df_3, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "\n",
    "df_upsampled = pd.concat([df_0, df_1,df_2, df_3])\n",
    "\n",
    "X_train_up = np.asarray(df_upsampled.iloc[:,0:1000])\n",
    "y_train_up = np.asarray(df_upsampled.iloc[:,1000])\n",
    "X_test_up = np.asarray(df_re[df_re.group==0].iloc[:,0:1000])\n",
    "y_test_up = np.asarray(df_re[df_re.group==0].iloc[:,1000])\n",
    "\n",
    "print('train label 分布:',np.bincount(y_train_up))\n",
    "print('test label 分布:',np.bincount(y_test_up))\n",
    "print('評分標準(只猜一群):',len(y_test_up[y_test_up == 1])/len(y_test_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.159578Z",
     "start_time": "2019-12-30T09:06:05.747556Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 715\n",
      "Accuracy: 0.39\n",
      "Accuracy: 0.39\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 399\n",
      "Accuracy: 0.91\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using Scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C = 10, random_state = 1)\n",
    "lr.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = lr.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %lr.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = lr.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %lr.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.171537Z",
     "start_time": "2019-12-30T09:06:06.161567Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50 405 398 319]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.531841Z",
     "start_time": "2019-12-30T09:06:06.524861Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3190104166666667\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:02.996605Z",
     "start_time": "2019-12-30T09:06:07.059178Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 675\n",
      "Accuracy: 0.42\n",
      "Accuracy: 0.42\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 13\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# training with SVM(RBF)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel = 'rbf', C = 100, gamma = 1000, random_state = 1)\n",
    "svm.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = svm.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %svm.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = svm.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %svm.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:03.011564Z",
     "start_time": "2019-12-30T09:07:03.000588Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 1165    0    7]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:03.027517Z",
     "start_time": "2019-12-30T09:07:03.016577Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bagging vs boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T06:01:11.511562Z",
     "start_time": "2020-01-04T06:00:45.221636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 508\n",
      "Accuracy: 0.57\n",
      "Accuracy: 0.57\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 1\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# training with forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=1, n_jobs=-1)\n",
    "forest.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = forest.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %forest.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = forest.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %forest.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T06:01:11.520538Z",
     "start_time": "2020-01-04T06:01:11.514554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 646 537   2]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T06:01:11.544474Z",
     "start_time": "2020-01-04T06:01:11.532506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4981481481481482\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T08:50:25.548776Z",
     "start_time": "2020-01-04T08:45:58.941802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 635\n",
      "Accuracy: 0.46\n",
      "Accuracy: 0.46\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 2657\n",
      "Accuracy: 0.55\n",
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2, criterion='entropy', random_state=1)\n",
    "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=300, learning_rate=0.1, random_state=1)\n",
    "ada = ada.fit(X_train_up,y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = ada.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %ada.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = ada.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %ada.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T08:50:25.573757Z",
     "start_time": "2020-01-04T08:50:25.563785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 355 824   5]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T08:50:25.604749Z",
     "start_time": "2020-01-04T08:50:25.576750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4187725631768953\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn and mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:50.886843Z",
     "start_time": "2020-01-08T11:14:00.721844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 565\n",
      "Accuracy: 0.52\n",
      "Accuracy: 0.52\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 1\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=1,hidden_layer_sizes=(100, ))\n",
    "mlp.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = mlp.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %mlp.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = mlp.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %mlp.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:50.897809Z",
     "start_time": "2020-01-08T11:14:50.889831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 568 544  73]\n",
      "0.4336569579288026\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))\n",
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:14:50.977595Z",
     "start_time": "2020-01-08T11:14:50.899803Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# NN\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_hidden : int (default: 30)\n",
    "        Number of hidden units.\n",
    "    l2 : float (default: 0.)\n",
    "        Lambda value for L2-regularization.\n",
    "        No regularization if l2=0. (default)\n",
    "    epochs : int (default: 100)\n",
    "        Number of passes over the training set.\n",
    "    eta : float (default: 0.001)\n",
    "        Learning rate.\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles training data every epoch if True to prevent circles.\n",
    "    minibatche_size : int (default: 1)\n",
    "        Number of training samples per minibatch.\n",
    "    seed : int (default: None)\n",
    "        Random seed for initalizing weights and shuffling.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    eval_ : dict\n",
    "      Dictionary collecting the cost, training accuracy,\n",
    "      and validation accuracy for each epoch during training.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 l2=0., epochs=100, eta=0.001,\n",
    "                 shuffle=True, minibatch_size=1, seed=None):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "\n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"Encode labels into one-hot representation\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        onehot : array, shape = (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "        return onehot.T\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Compute logistic function (sigmoid)\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"Compute forward propagation step\"\"\"\n",
    "\n",
    "        # step 1: net input of hidden layer\n",
    "        # [n_samples, n_features] dot [n_features, n_hidden]\n",
    "        # -> [n_samples, n_hidden]\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "\n",
    "        # step 2: activation of hidden layer\n",
    "        a_h = self._sigmoid(z_h)\n",
    "\n",
    "        # step 3: net input of output layer\n",
    "        # [n_samples, n_hidden] dot [n_hidden, n_classlabels]\n",
    "        # -> [n_samples, n_classlabels]\n",
    "\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "\n",
    "        # step 4: activation output layer\n",
    "        a_out = self._sigmoid(z_out)\n",
    "\n",
    "        return z_h, a_h, z_out, a_out\n",
    "\n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"Compute cost function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_enc : array, shape = (n_samples, n_labels)\n",
    "            one-hot encoded class labels.\n",
    "        output : array, shape = [n_samples, n_output_units]\n",
    "            Activation of the output layer (forward propagation)\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        cost : float\n",
    "            Regularized cost\n",
    "\n",
    "        \"\"\"\n",
    "        L2_term = (self.l2 *\n",
    "                   (np.sum(self.w_h ** 2.) +\n",
    "                    np.sum(self.w_out ** 2.)))\n",
    "\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "\n",
    "        \"\"\"\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X_train : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        y_train : array, shape = [n_samples]\n",
    "            Target class labels.\n",
    "        X_valid : array, shape = [n_samples, n_features]\n",
    "            Sample features for validation during training\n",
    "        y_valid : array, shape = [n_samples]\n",
    "            Sample labels for validation during training\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0]  # number of class labels\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        ########################\n",
    "        # Weight initialization\n",
    "        ########################\n",
    "\n",
    "        # weights for input -> hidden\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                      size=(n_features, self.n_hidden))\n",
    "\n",
    "        # weights for hidden -> output\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                        size=(self.n_hidden, n_output))\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # for progress formatting\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "\n",
    "        # iterate over training epochs\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # iterate over minibatches\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # forward propagation\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "\n",
    "                ##################\n",
    "                # Backpropagation\n",
    "                ##################\n",
    "\n",
    "                # [n_samples, n_classlabels]\n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "\n",
    "                # [n_samples, n_hidden]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "\n",
    "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
    "                # -> [n_samples, n_hidden]\n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) *\n",
    "                           sigmoid_derivative_h)\n",
    "\n",
    "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
    "                # -> [n_features, n_hidden]\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "\n",
    "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
    "                # -> [n_hidden, n_classlabels]\n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "\n",
    "                # Regularization and weight updates\n",
    "                delta_w_h = (grad_w_h + self.l2*self.w_h)\n",
    "                delta_b_h = grad_b_h # bias is not regularized\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "\n",
    "                delta_w_out = (grad_w_out + self.l2*self.w_out)\n",
    "                delta_b_out = grad_b_out  # bias is not regularized\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "\n",
    "            #############\n",
    "            # Evaluation\n",
    "            #############\n",
    "\n",
    "            # Evaluation after each epoch during training\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "            \n",
    "            cost = self._compute_cost(y_enc=y_train_enc,\n",
    "                                      output=a_out)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) /\n",
    "                         X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) /\n",
    "                         X_valid.shape[0])\n",
    "\n",
    "            sys.stderr.write('\\r%0*d/%d | Cost: %.2f '\n",
    "                             '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:17:17.245861Z",
     "start_time": "2020-01-08T11:14:50.982584Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200/200 | Cost: 7205.65 | Train/Valid Acc.: 76.04%/49.11%  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetMLP at 0x225800ff860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "nn = NeuralNetMLP(n_hidden=100, \n",
    "                  l2=0.01, \n",
    "                  epochs=n_epochs, \n",
    "                  eta=0.0005,\n",
    "                  minibatch_size=100, \n",
    "                  shuffle=True,\n",
    "                  seed=1)\n",
    "\n",
    "nn.fit(X_train_up,y_train_up,\n",
    "       X_test_up,y_test_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:19:40.903576Z",
     "start_time": "2020-01-08T11:19:39.916800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(nn.epochs), nn.eval_['cost'])\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "#plt.savefig('images/12_07.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:17:18.536945Z",
     "start_time": "2020-01-08T11:17:18.335911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 49.11%\n",
      "\n",
      "test --- train\n",
      "\n",
      "Train accuracy: 76.04%\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test_up)\n",
    "acc = (np.sum(y_pred == y_test_up)\n",
    "       .astype(np.float) / X_test_up.shape[0])\n",
    "\n",
    "print('Test accuracy: %.2f%%' % (acc * 100))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "y_pred2 = nn.predict(X_train_up)\n",
    "acc2 = (np.sum(y_pred2 == y_train_up)\n",
    "       .astype(np.float) / X_train_up.shape[0])\n",
    "\n",
    "print('Train accuracy: %.2f%%' % (acc2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:17:18.554444Z",
     "start_time": "2020-01-08T11:17:18.544463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12 475 481 217]\n",
      "0.3727144866385373\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))\n",
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
