{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP & train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:18:06.700802Z",
     "start_time": "2020-01-08T11:18:02.395896Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f = open('womantalk_max.csv')\n",
    "df= pd.read_csv(f, header = None)\n",
    "df = df.fillna('0')\n",
    "\n",
    "X = df.iloc[:, 2].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:18:06.946758Z",
     "start_time": "2020-01-08T11:18:06.705792Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing : extracting feature vector from X_train\n",
    "# 拿掉換行和標點符號\n",
    "import re\n",
    "from zhon.hanzi import punctuation\n",
    "import string\n",
    "\n",
    "eng_punc = string.punctuation\n",
    "def preprocessor(text):\n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    re_punctuation = \"[{}]+\".format(punctuation)  #拿掉中文標點\n",
    "    text = re.sub(re_punctuation, \"\", text)\n",
    "    \n",
    "    re_punctuation_eng = \"[{}]+\".format(eng_punc) #拿掉英文標點\n",
    "    text = re.sub(re_punctuation_eng, \"\", text)    \n",
    "    \n",
    "    ptt_punc = '\\n\\t ※'\n",
    "    re_punctuation_ptt = \"[{}]+\".format(ptt_punc) #拿掉其他無用字元\n",
    "    text = re.sub(re_punctuation_ptt, \"\", text)  \n",
    "    \n",
    "    text = re.sub('[0-9A-Za-z]+','',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X[i] = preprocessor(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:18:31.509184Z",
     "start_time": "2020-01-08T11:18:06.951747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\User\\Desktop\\pytry\\final\\train_all\\jieba_dict\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.u4dc008d2500e3c796bdd282f2ecbc9e7.cache\n",
      "Loading model cost 2.144 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing : tf-idf using jieba\n",
    "# preprocessing : 移除stop word\n",
    "import jieba.analyse\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary(\"jieba_dict/dict.txt.big.txt\")\n",
    "tags = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    tags.append(jieba.analyse.extract_tags(X[i], topK=50, withWeight=True))\n",
    "stopWords = []\n",
    "with open('stop_word/stop_word.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data)\n",
    "        \n",
    "X_cut = X\n",
    "X_cut_stop = X\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X_cut[i] = jieba.cut(X[i], cut_all=False)\n",
    "    X_cut_stop[i] = list(filter(lambda a: a not in stopWords and a != '\\n', X_cut[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:18:31.541140Z",
     "start_time": "2020-01-08T11:18:31.513189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nfor i in range(0, len(y)):\\n    if y[i] == '爆':\\n        y[i] = 1\\n    elif y[i][0] == 'X':\\n        y[i] = 0\\n    else:\\n        y[i] = int(y[i])\\n        if y[i] == 0:\\n            y[i] = 0\\n        elif y[i] >= 1 and y[i] <= 10:\\n            y[i] = 0\\n        elif y[i] >= 11 and y[i] <= 50:\\n            y[i] = 1\\n        elif y[i] >= 51 and y[i] <= 99:\\n            y[i] = 1\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing : labeling y_train\n",
    "# encoding of 推噓 : \n",
    "import math\n",
    "\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == '爆':\n",
    "        y[i] = 3\n",
    "    elif y[i][0] == 'X':\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = int(y[i])\n",
    "        if y[i] == 0:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 1 and y[i] <= 10:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 11 and y[i] <= 50:\n",
    "            y[i] = 2\n",
    "        elif y[i] >= 51 and y[i] <= 99:\n",
    "            y[i] = 3\n",
    "'''    \n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == '爆':\n",
    "        y[i] = 1\n",
    "    elif y[i][0] == 'X':\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = int(y[i])\n",
    "        if y[i] == 0:\n",
    "            y[i] = 0\n",
    "        elif y[i] >= 1 and y[i] <= 10:\n",
    "            y[i] = 0\n",
    "        elif y[i] >= 11 and y[i] <= 50:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 51 and y[i] <= 99:\n",
    "            y[i] = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:22:29.414278Z",
     "start_time": "2020-01-08T11:18:31.555110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing : 轉換成NTLK可以使用的格式\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "X_cut_NTLK = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    article = ''\n",
    "    for word in X_cut_stop[i]:\n",
    "        article = article + word\n",
    "        article = article + ' '\n",
    "    X_cut_NTLK = np.hstack((X_cut_NTLK, article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:22:30.296418Z",
     "start_time": "2020-01-08T11:22:29.419250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing : Bag of Word\n",
    "# Preprocessing : Term frequency - inverse document frequency (tf - idf) using NTLK\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(max_features=1000)\n",
    "bag = count.fit_transform(X_cut_NTLK)\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf = True,\n",
    "                         norm = 'l2',\n",
    "                         smooth_idf = True)\n",
    "X_bag_idf = tfidf.fit_transform(bag)\n",
    "print(X_bag_idf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:22:30.335314Z",
     "start_time": "2020-01-08T11:22:30.328332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3967\n",
      "3967\n"
     ]
    }
   ],
   "source": [
    "print(y.shape[0])\n",
    "print(X_bag_idf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:22:30.352276Z",
     "start_time": "2020-01-08T11:22:30.339303Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [  35 2812  847  273]\n",
      "Labels counts in y_train: [  24 1968  593  191]\n",
      "Labels counts in y_test: [ 11 844 254  82]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = y.astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_bag_idf, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:22:30.626564Z",
     "start_time": "2020-01-08T11:22:30.357258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2776\n",
      "1191\n",
      "3967\n",
      "3967\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.toarray()[:,0]))\n",
    "print(len(X_test.toarray()[:,0]))\n",
    "\n",
    "X_all = np.concatenate((X_train.toarray(),X_test.toarray()),axis=0)\n",
    "y_all = np.concatenate((y_train,y_test))\n",
    "\n",
    "print(len(X_all[:,0]))\n",
    "print(len(y_all))\n",
    "\n",
    "group = np.zeros(len(y_all), dtype=np.int)\n",
    "group[0:len(X_train.toarray()[:,0])] = group[0:len(X_train.toarray()[:,0])]+1\n",
    "df_re = pd.DataFrame(X_all)\n",
    "df_re['label'] = y_all\n",
    "df_re['group'] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:22:31.327224Z",
     "start_time": "2020-01-08T11:22:30.673439Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label 分布: [1968 1968 1968 1968]\n",
      "test label 分布: [ 11 844 254  82]\n",
      "評分標準(只猜一群): 0.7086481947942905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_0 = df_re[df_re.group==1][df_re.label==0]\n",
    "df_1 = df_re[df_re.group==1][df_re.label==1]\n",
    "df_2 = df_re[df_re.group==1][df_re.label==2]\n",
    "df_3 = df_re[df_re.group==1][df_re.label==3]\n",
    "\n",
    "df_0 = resample(df_0, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_1 = resample(df_1, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_2 = resample(df_2, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_3 = resample(df_3, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "\n",
    "df_upsampled = pd.concat([df_0, df_1,df_2, df_3])\n",
    "\n",
    "X_train_up = np.asarray(df_upsampled.iloc[:,0:1000])\n",
    "y_train_up = np.asarray(df_upsampled.iloc[:,1000])\n",
    "X_test_up = np.asarray(df_re[df_re.group==0].iloc[:,0:1000])\n",
    "y_test_up = np.asarray(df_re[df_re.group==0].iloc[:,1000])\n",
    "\n",
    "print('train label 分布:',np.bincount(y_train_up))\n",
    "print('test label 分布:',np.bincount(y_test_up))\n",
    "print('評分標準(只猜一群):',len(y_test_up[y_test_up == 1])/len(y_test_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.159578Z",
     "start_time": "2019-12-30T09:06:05.747556Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 715\n",
      "Accuracy: 0.39\n",
      "Accuracy: 0.39\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 399\n",
      "Accuracy: 0.91\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using Scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C = 10, random_state = 1)\n",
    "lr.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = lr.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %lr.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = lr.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %lr.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.171537Z",
     "start_time": "2019-12-30T09:06:06.161567Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50 405 398 319]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.531841Z",
     "start_time": "2019-12-30T09:06:06.524861Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3190104166666667\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:02.996605Z",
     "start_time": "2019-12-30T09:06:07.059178Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 675\n",
      "Accuracy: 0.42\n",
      "Accuracy: 0.42\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 13\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# training with SVM(RBF)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel = 'rbf', C = 100, gamma = 1000, random_state = 1)\n",
    "svm.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = svm.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %svm.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = svm.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %svm.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:03.011564Z",
     "start_time": "2019-12-30T09:07:03.000588Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 1165    0    7]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:03.027517Z",
     "start_time": "2019-12-30T09:07:03.016577Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bagging vs boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T03:54:27.065127Z",
     "start_time": "2020-01-03T03:54:08.895562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 371\n",
      "Accuracy: 0.69\n",
      "Accuracy: 0.69\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 1\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# training with forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=1, n_jobs=-1)\n",
    "forest.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = forest.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %forest.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = forest.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %forest.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T03:54:27.071110Z",
     "start_time": "2020-01-03T03:54:27.067121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1 1147   43]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T03:54:27.079089Z",
     "start_time": "2020-01-03T03:54:27.073105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17777777777777778\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T07:06:16.469277Z",
     "start_time": "2020-01-03T07:04:18.892163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 446\n",
      "Accuracy: 0.63\n",
      "Accuracy: 0.63\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 2781\n",
      "Accuracy: 0.65\n",
      "Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, criterion='entropy', random_state=1)\n",
    "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=200, learning_rate=0.1, random_state=1)\n",
    "ada = ada.fit(X_train_up,y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = ada.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %ada.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = ada.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %ada.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T07:06:16.478191Z",
     "start_time": "2020-01-03T07:06:16.473204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 973 203  15]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T07:06:16.502140Z",
     "start_time": "2020-01-03T07:06:16.485185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2191780821917808\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn and mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:24:26.153075Z",
     "start_time": "2020-01-08T11:22:31.329228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 578\n",
      "Accuracy: 0.51\n",
      "Accuracy: 0.51\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 1\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=1,hidden_layer_sizes=(100, ))\n",
    "mlp.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = mlp.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %mlp.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = mlp.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %mlp.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:24:26.165034Z",
     "start_time": "2020-01-08T11:24:26.157056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4 706 363 118]\n",
      "0.19135802469135801\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))\n",
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:24:26.233364Z",
     "start_time": "2020-01-08T11:24:26.173011Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# NN\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_hidden : int (default: 30)\n",
    "        Number of hidden units.\n",
    "    l2 : float (default: 0.)\n",
    "        Lambda value for L2-regularization.\n",
    "        No regularization if l2=0. (default)\n",
    "    epochs : int (default: 100)\n",
    "        Number of passes over the training set.\n",
    "    eta : float (default: 0.001)\n",
    "        Learning rate.\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles training data every epoch if True to prevent circles.\n",
    "    minibatche_size : int (default: 1)\n",
    "        Number of training samples per minibatch.\n",
    "    seed : int (default: None)\n",
    "        Random seed for initalizing weights and shuffling.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    eval_ : dict\n",
    "      Dictionary collecting the cost, training accuracy,\n",
    "      and validation accuracy for each epoch during training.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 l2=0., epochs=100, eta=0.001,\n",
    "                 shuffle=True, minibatch_size=1, seed=None):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "\n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"Encode labels into one-hot representation\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        onehot : array, shape = (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "        return onehot.T\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Compute logistic function (sigmoid)\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"Compute forward propagation step\"\"\"\n",
    "\n",
    "        # step 1: net input of hidden layer\n",
    "        # [n_samples, n_features] dot [n_features, n_hidden]\n",
    "        # -> [n_samples, n_hidden]\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "\n",
    "        # step 2: activation of hidden layer\n",
    "        a_h = self._sigmoid(z_h)\n",
    "\n",
    "        # step 3: net input of output layer\n",
    "        # [n_samples, n_hidden] dot [n_hidden, n_classlabels]\n",
    "        # -> [n_samples, n_classlabels]\n",
    "\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "\n",
    "        # step 4: activation output layer\n",
    "        a_out = self._sigmoid(z_out)\n",
    "\n",
    "        return z_h, a_h, z_out, a_out\n",
    "\n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"Compute cost function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_enc : array, shape = (n_samples, n_labels)\n",
    "            one-hot encoded class labels.\n",
    "        output : array, shape = [n_samples, n_output_units]\n",
    "            Activation of the output layer (forward propagation)\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        cost : float\n",
    "            Regularized cost\n",
    "\n",
    "        \"\"\"\n",
    "        L2_term = (self.l2 *\n",
    "                   (np.sum(self.w_h ** 2.) +\n",
    "                    np.sum(self.w_out ** 2.)))\n",
    "\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "\n",
    "        \"\"\"\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X_train : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        y_train : array, shape = [n_samples]\n",
    "            Target class labels.\n",
    "        X_valid : array, shape = [n_samples, n_features]\n",
    "            Sample features for validation during training\n",
    "        y_valid : array, shape = [n_samples]\n",
    "            Sample labels for validation during training\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0]  # number of class labels\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        ########################\n",
    "        # Weight initialization\n",
    "        ########################\n",
    "\n",
    "        # weights for input -> hidden\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                      size=(n_features, self.n_hidden))\n",
    "\n",
    "        # weights for hidden -> output\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                        size=(self.n_hidden, n_output))\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # for progress formatting\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "\n",
    "        # iterate over training epochs\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # iterate over minibatches\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # forward propagation\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "\n",
    "                ##################\n",
    "                # Backpropagation\n",
    "                ##################\n",
    "\n",
    "                # [n_samples, n_classlabels]\n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "\n",
    "                # [n_samples, n_hidden]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "\n",
    "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
    "                # -> [n_samples, n_hidden]\n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) *\n",
    "                           sigmoid_derivative_h)\n",
    "\n",
    "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
    "                # -> [n_features, n_hidden]\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "\n",
    "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
    "                # -> [n_hidden, n_classlabels]\n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "\n",
    "                # Regularization and weight updates\n",
    "                delta_w_h = (grad_w_h + self.l2*self.w_h)\n",
    "                delta_b_h = grad_b_h # bias is not regularized\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "\n",
    "                delta_w_out = (grad_w_out + self.l2*self.w_out)\n",
    "                delta_b_out = grad_b_out  # bias is not regularized\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "\n",
    "            #############\n",
    "            # Evaluation\n",
    "            #############\n",
    "\n",
    "            # Evaluation after each epoch during training\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "            \n",
    "            cost = self._compute_cost(y_enc=y_train_enc,\n",
    "                                      output=a_out)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) /\n",
    "                         X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) /\n",
    "                         X_valid.shape[0])\n",
    "\n",
    "            sys.stderr.write('\\r%0*d/%d | Cost: %.2f '\n",
    "                             '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:22.648592Z",
     "start_time": "2020-01-08T11:24:26.273255Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200/200 | Cost: 9289.06 | Train/Valid Acc.: 78.06%/44.84%  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetMLP at 0x1eb9cd2c0b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "nn = NeuralNetMLP(n_hidden=100, \n",
    "                  l2=0.01, \n",
    "                  epochs=n_epochs, \n",
    "                  eta=0.0005,\n",
    "                  minibatch_size=100, \n",
    "                  shuffle=True,\n",
    "                  seed=1)\n",
    "\n",
    "nn.fit(X_train_up,y_train_up,\n",
    "       X_test_up,y_test_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:32:17.891673Z",
     "start_time": "2020-01-08T11:32:17.336157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(nn.epochs), nn.eval_['cost'])\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "#plt.savefig('images/12_07.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:24.231934Z",
     "start_time": "2020-01-08T11:29:24.012269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 44.84%\n",
      "\n",
      "test --- train\n",
      "\n",
      "Train accuracy: 78.06%\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test_up)\n",
    "acc = (np.sum(y_pred == y_test_up)\n",
    "       .astype(np.float) / X_test_up.shape[0])\n",
    "\n",
    "print('Test accuracy: %.2f%%' % (acc * 100))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "y_pred2 = nn.predict(X_train_up)\n",
    "acc2 = (np.sum(y_pred2 == y_train_up)\n",
    "       .astype(np.float) / X_train_up.shape[0])\n",
    "\n",
    "print('Train accuracy: %.2f%%' % (acc2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:24.244976Z",
     "start_time": "2020-01-08T11:29:24.233927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20 574 312 285]\n",
      "0.15048543689320387\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))\n",
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
