{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP & train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:13:46.468921Z",
     "start_time": "2020-01-08T11:13:45.284064Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f = open('sex_max.csv')\n",
    "df= pd.read_csv(f, header = None)\n",
    "df = df.fillna('0')\n",
    "\n",
    "X = df.iloc[:, 2].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:13:46.976566Z",
     "start_time": "2020-01-08T11:13:46.474922Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing : extracting feature vector from X_train\n",
    "# 拿掉換行和標點符號\n",
    "import re\n",
    "from zhon.hanzi import punctuation\n",
    "import string\n",
    "\n",
    "eng_punc = string.punctuation\n",
    "def preprocessor(text):\n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    re_punctuation = \"[{}]+\".format(punctuation)  #拿掉中文標點\n",
    "    text = re.sub(re_punctuation, \"\", text)\n",
    "    \n",
    "    re_punctuation_eng = \"[{}]+\".format(eng_punc) #拿掉英文標點\n",
    "    text = re.sub(re_punctuation_eng, \"\", text)    \n",
    "    \n",
    "    ptt_punc = '\\n\\t ※'\n",
    "    re_punctuation_ptt = \"[{}]+\".format(ptt_punc) #拿掉其他無用字元\n",
    "    text = re.sub(re_punctuation_ptt, \"\", text)  \n",
    "    \n",
    "    text = re.sub('[0-9A-Za-z]+','',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X[i] = preprocessor(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:15:06.082760Z",
     "start_time": "2020-01-08T11:13:46.978560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\User\\Desktop\\pytry\\final\\train_all\\jieba_dict\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.u4dc008d2500e3c796bdd282f2ecbc9e7.cache\n",
      "Loading model cost 1.826 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing : tf-idf using jieba\n",
    "# preprocessing : 移除stop word\n",
    "import jieba.analyse\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary(\"jieba_dict/dict.txt.big.txt\")\n",
    "tags = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    tags.append(jieba.analyse.extract_tags(X[i], topK=50, withWeight=True))\n",
    "stopWords = []\n",
    "with open('stop_word/stop_word.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data)\n",
    "        \n",
    "X_cut = X\n",
    "X_cut_stop = X\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X_cut[i] = jieba.cut(X[i], cut_all=False)\n",
    "    X_cut_stop[i] = list(filter(lambda a: a not in stopWords and a != '\\n', X_cut[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:15:06.112195Z",
     "start_time": "2020-01-08T11:15:06.085266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nfor i in range(0, len(y)):\\n    if y[i] == '爆':\\n        y[i] = 1\\n    elif y[i][0] == 'X':\\n        y[i] = 0\\n    else:\\n        y[i] = int(y[i])\\n        if y[i] == 0:\\n            y[i] = 0\\n        elif y[i] >= 1 and y[i] <= 10:\\n            y[i] = 0\\n        elif y[i] >= 11 and y[i] <= 50:\\n            y[i] = 1\\n        elif y[i] >= 51 and y[i] <= 99:\\n            y[i] = 1\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing : labeling y_train\n",
    "# encoding of 推噓 : \n",
    "import math\n",
    "\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == '爆':\n",
    "        y[i] = 3\n",
    "    elif y[i][0] == 'X':\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = int(y[i])\n",
    "        if y[i] == 0:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 1 and y[i] <= 10:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 11 and y[i] <= 50:\n",
    "            y[i] = 2\n",
    "        elif y[i] >= 51 and y[i] <= 99:\n",
    "            y[i] = 3\n",
    "'''    \n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == '爆':\n",
    "        y[i] = 1\n",
    "    elif y[i][0] == 'X':\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = int(y[i])\n",
    "        if y[i] == 0:\n",
    "            y[i] = 0\n",
    "        elif y[i] >= 1 and y[i] <= 10:\n",
    "            y[i] = 0\n",
    "        elif y[i] >= 11 and y[i] <= 50:\n",
    "            y[i] = 1\n",
    "        elif y[i] >= 51 and y[i] <= 99:\n",
    "            y[i] = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:50.173088Z",
     "start_time": "2020-01-08T11:15:06.116182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing : 轉換成NTLK可以使用的格式\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "X_cut_NTLK = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    article = ''\n",
    "    for word in X_cut_stop[i]:\n",
    "        article = article + word\n",
    "        article = article + ' '\n",
    "    X_cut_NTLK = np.hstack((X_cut_NTLK, article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:53.595636Z",
     "start_time": "2020-01-08T11:31:50.504186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing : Bag of Word\n",
    "# Preprocessing : Term frequency - inverse document frequency (tf - idf) using NTLK\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(max_features=1000)\n",
    "bag = count.fit_transform(X_cut_NTLK)\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf = True,\n",
    "                         norm = 'l2',\n",
    "                         smooth_idf = True)\n",
    "X_bag_idf = tfidf.fit_transform(bag)\n",
    "print(X_bag_idf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:53.609614Z",
     "start_time": "2020-01-08T11:31:53.597630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3945\n",
      "3945\n"
     ]
    }
   ],
   "source": [
    "print(y.shape[0])\n",
    "print(X_bag_idf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:53.759196Z",
     "start_time": "2020-01-08T11:31:53.631539Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [  38 1898 1572  437]\n",
      "Labels counts in y_train: [  27 1328 1100  306]\n",
      "Labels counts in y_test: [ 11 570 472 131]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = y.astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_bag_idf, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:53.998555Z",
     "start_time": "2020-01-08T11:31:53.761191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2761\n",
      "1184\n",
      "3945\n",
      "3945\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.toarray()[:,0]))\n",
    "print(len(X_test.toarray()[:,0]))\n",
    "\n",
    "X_all = np.concatenate((X_train.toarray(),X_test.toarray()),axis=0)\n",
    "y_all = np.concatenate((y_train,y_test))\n",
    "\n",
    "print(len(X_all[:,0]))\n",
    "print(len(y_all))\n",
    "\n",
    "group = np.zeros(len(y_all), dtype=np.int)\n",
    "group[0:len(X_train.toarray()[:,0])] = group[0:len(X_train.toarray()[:,0])]+1\n",
    "df_re = pd.DataFrame(X_all)\n",
    "df_re['label'] = y_all\n",
    "df_re['group'] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:54.481266Z",
     "start_time": "2020-01-08T11:31:54.021495Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label 分布: [1328 1328 1328 1328]\n",
      "test label 分布: [ 11 570 472 131]\n",
      "評分標準(只猜一群): 0.4814189189189189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_0 = df_re[df_re.group==1][df_re.label==0]\n",
    "df_1 = df_re[df_re.group==1][df_re.label==1]\n",
    "df_2 = df_re[df_re.group==1][df_re.label==2]\n",
    "df_3 = df_re[df_re.group==1][df_re.label==3]\n",
    "\n",
    "df_0 = resample(df_0, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_1 = resample(df_1, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_2 = resample(df_2, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "df_3 = resample(df_3, replace=True, n_samples=np.bincount(y_train).max(), random_state=123)\n",
    "\n",
    "df_upsampled = pd.concat([df_0, df_1,df_2, df_3])\n",
    "\n",
    "X_train_up = np.asarray(df_upsampled.iloc[:,0:1000])\n",
    "y_train_up = np.asarray(df_upsampled.iloc[:,1000])\n",
    "X_test_up = np.asarray(df_re[df_re.group==0].iloc[:,0:1000])\n",
    "y_test_up = np.asarray(df_re[df_re.group==0].iloc[:,1000])\n",
    "\n",
    "print('train label 分布:',np.bincount(y_train_up))\n",
    "print('test label 分布:',np.bincount(y_test_up))\n",
    "print('評分標準(只猜一群):',len(y_test_up[y_test_up == 1])/len(y_test_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.159578Z",
     "start_time": "2019-12-30T09:06:05.747556Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 715\n",
      "Accuracy: 0.39\n",
      "Accuracy: 0.39\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 399\n",
      "Accuracy: 0.91\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using Scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C = 10, random_state = 1)\n",
    "lr.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = lr.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %lr.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = lr.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %lr.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.171537Z",
     "start_time": "2019-12-30T09:06:06.161567Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50 405 398 319]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:06:06.531841Z",
     "start_time": "2019-12-30T09:06:06.524861Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3190104166666667\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:02.996605Z",
     "start_time": "2019-12-30T09:06:07.059178Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 675\n",
      "Accuracy: 0.42\n",
      "Accuracy: 0.42\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 13\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# training with SVM(RBF)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel = 'rbf', C = 100, gamma = 1000, random_state = 1)\n",
    "svm.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = svm.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %svm.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = svm.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %svm.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:03.011564Z",
     "start_time": "2019-12-30T09:07:03.000588Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 1165    0    7]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T09:07:03.027517Z",
     "start_time": "2019-12-30T09:07:03.016577Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bagging vs boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T06:11:39.438534Z",
     "start_time": "2020-01-04T06:11:25.169318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 625\n",
      "Accuracy: 0.47\n",
      "Accuracy: 0.47\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 0\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# training with forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=1, n_jobs=-1)\n",
    "forest.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = forest.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %forest.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = forest.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %forest.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T06:11:39.452495Z",
     "start_time": "2020-01-04T06:11:39.444515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 552 615  17]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T06:11:39.467463Z",
     "start_time": "2020-01-04T06:11:39.457503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4154818325434439\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T09:29:33.318915Z",
     "start_time": "2020-01-04T08:45:12.248661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 667\n",
      "Accuracy: 0.44\n",
      "Accuracy: 0.44\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 2069\n",
      "Accuracy: 0.61\n",
      "Accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2, criterion='entropy', random_state=1)\n",
    "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=5000, learning_rate=0.1, random_state=1)\n",
    "ada = ada.fit(X_train_up,y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = ada.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %ada.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = ada.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %ada.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T09:29:33.398204Z",
     "start_time": "2020-01-04T09:29:33.359805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3 495 566 120]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T09:29:33.415157Z",
     "start_time": "2020-01-04T09:29:33.404187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn and mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:32:27.309483Z",
     "start_time": "2020-01-08T11:31:54.484261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 682\n",
      "Accuracy: 0.42\n",
      "Accuracy: 0.42\n",
      "\n",
      "test --- train\n",
      "\n",
      "Misclassified samples: 0\n",
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=1,hidden_layer_sizes=(100, ))\n",
    "mlp.fit(X_train_up, y_train_up)\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred = mlp.predict(X_test_up)\n",
    "print('Misclassified samples: %d' % (y_test_up != y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_test_up, y_pred))\n",
    "print('Accuracy: %.2f' %mlp.score(X_test_up, y_test_up))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "# Prediction and Performance Measurement\n",
    "y_pred2 = mlp.predict(X_train_up)\n",
    "print('Misclassified samples: %d' % (y_train_up != y_pred2).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.2f' %accuracy_score(y_train_up, y_pred2))\n",
    "print('Accuracy: %.2f' %mlp.score(X_train_up, y_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:32:27.318460Z",
     "start_time": "2020-01-08T11:32:27.311479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5 500 446 233]\n",
      "0.33284671532846716\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))\n",
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:32:27.386279Z",
     "start_time": "2020-01-08T11:32:27.320454Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# NN\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_hidden : int (default: 30)\n",
    "        Number of hidden units.\n",
    "    l2 : float (default: 0.)\n",
    "        Lambda value for L2-regularization.\n",
    "        No regularization if l2=0. (default)\n",
    "    epochs : int (default: 100)\n",
    "        Number of passes over the training set.\n",
    "    eta : float (default: 0.001)\n",
    "        Learning rate.\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles training data every epoch if True to prevent circles.\n",
    "    minibatche_size : int (default: 1)\n",
    "        Number of training samples per minibatch.\n",
    "    seed : int (default: None)\n",
    "        Random seed for initalizing weights and shuffling.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    eval_ : dict\n",
    "      Dictionary collecting the cost, training accuracy,\n",
    "      and validation accuracy for each epoch during training.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 l2=0., epochs=100, eta=0.001,\n",
    "                 shuffle=True, minibatch_size=1, seed=None):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "\n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"Encode labels into one-hot representation\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        onehot : array, shape = (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "        return onehot.T\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Compute logistic function (sigmoid)\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"Compute forward propagation step\"\"\"\n",
    "\n",
    "        # step 1: net input of hidden layer\n",
    "        # [n_samples, n_features] dot [n_features, n_hidden]\n",
    "        # -> [n_samples, n_hidden]\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "\n",
    "        # step 2: activation of hidden layer\n",
    "        a_h = self._sigmoid(z_h)\n",
    "\n",
    "        # step 3: net input of output layer\n",
    "        # [n_samples, n_hidden] dot [n_hidden, n_classlabels]\n",
    "        # -> [n_samples, n_classlabels]\n",
    "\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "\n",
    "        # step 4: activation output layer\n",
    "        a_out = self._sigmoid(z_out)\n",
    "\n",
    "        return z_h, a_h, z_out, a_out\n",
    "\n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"Compute cost function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_enc : array, shape = (n_samples, n_labels)\n",
    "            one-hot encoded class labels.\n",
    "        output : array, shape = [n_samples, n_output_units]\n",
    "            Activation of the output layer (forward propagation)\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        cost : float\n",
    "            Regularized cost\n",
    "\n",
    "        \"\"\"\n",
    "        L2_term = (self.l2 *\n",
    "                   (np.sum(self.w_h ** 2.) +\n",
    "                    np.sum(self.w_out ** 2.)))\n",
    "\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "\n",
    "        \"\"\"\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X_train : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        y_train : array, shape = [n_samples]\n",
    "            Target class labels.\n",
    "        X_valid : array, shape = [n_samples, n_features]\n",
    "            Sample features for validation during training\n",
    "        y_valid : array, shape = [n_samples]\n",
    "            Sample labels for validation during training\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0]  # number of class labels\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        ########################\n",
    "        # Weight initialization\n",
    "        ########################\n",
    "\n",
    "        # weights for input -> hidden\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                      size=(n_features, self.n_hidden))\n",
    "\n",
    "        # weights for hidden -> output\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                        size=(self.n_hidden, n_output))\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # for progress formatting\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "\n",
    "        # iterate over training epochs\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # iterate over minibatches\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # forward propagation\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "\n",
    "                ##################\n",
    "                # Backpropagation\n",
    "                ##################\n",
    "\n",
    "                # [n_samples, n_classlabels]\n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "\n",
    "                # [n_samples, n_hidden]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "\n",
    "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
    "                # -> [n_samples, n_hidden]\n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) *\n",
    "                           sigmoid_derivative_h)\n",
    "\n",
    "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
    "                # -> [n_features, n_hidden]\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "\n",
    "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
    "                # -> [n_hidden, n_classlabels]\n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "\n",
    "                # Regularization and weight updates\n",
    "                delta_w_h = (grad_w_h + self.l2*self.w_h)\n",
    "                delta_b_h = grad_b_h # bias is not regularized\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "\n",
    "                delta_w_out = (grad_w_out + self.l2*self.w_out)\n",
    "                delta_b_out = grad_b_out  # bias is not regularized\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "\n",
    "            #############\n",
    "            # Evaluation\n",
    "            #############\n",
    "\n",
    "            # Evaluation after each epoch during training\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "            \n",
    "            cost = self._compute_cost(y_enc=y_train_enc,\n",
    "                                      output=a_out)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) /\n",
    "                         X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) /\n",
    "                         X_valid.shape[0])\n",
    "\n",
    "            sys.stderr.write('\\r%0*d/%d | Cost: %.2f '\n",
    "                             '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:33:13.695867Z",
     "start_time": "2020-01-08T11:32:27.390268Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200/200 | Cost: 7349.81 | Train/Valid Acc.: 66.72%/35.73%  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetMLP at 0x1af877e0dd8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "nn = NeuralNetMLP(n_hidden=100, \n",
    "                  l2=0.01, \n",
    "                  epochs=n_epochs, \n",
    "                  eta=0.0005,\n",
    "                  minibatch_size=100, \n",
    "                  shuffle=True,\n",
    "                  seed=1)\n",
    "\n",
    "nn.fit(X_train_up,y_train_up,\n",
    "       X_test_up,y_test_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:33:19.326405Z",
     "start_time": "2020-01-08T11:33:19.196753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(nn.epochs), nn.eval_['cost'])\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "#plt.savefig('images/12_07.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:33:16.536046Z",
     "start_time": "2020-01-08T11:33:16.435293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 35.73%\n",
      "\n",
      "test --- train\n",
      "\n",
      "Train accuracy: 66.72%\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test_up)\n",
    "acc = (np.sum(y_pred == y_test_up)\n",
    "       .astype(np.float) / X_test_up.shape[0])\n",
    "\n",
    "print('Test accuracy: %.2f%%' % (acc * 100))\n",
    "\n",
    "print('\\ntest --- train\\n')\n",
    "\n",
    "y_pred2 = nn.predict(X_train_up)\n",
    "acc2 = (np.sum(y_pred2 == y_train_up)\n",
    "       .astype(np.float) / X_train_up.shape[0])\n",
    "\n",
    "print('Train accuracy: %.2f%%' % (acc2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:33:16.547992Z",
     "start_time": "2020-01-08T11:33:16.539017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44 304 350 486]\n",
      "0.2690124858115778\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_pred))\n",
    "j = y_pred[y_pred != 1]\n",
    "k = y_test_up[y_pred != 1]\n",
    "\n",
    "print(sum(j==k)/(len(j)+1))  ## 小群的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
